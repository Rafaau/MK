{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\ntext = \"Artificial intelligence (AI) is intelligence-perceiving, synthesizing, and inferring information-demonstrated by machines, as opposed to intelligence displayed by non-human animals or by humans\"\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([text])\ntotal_words = len(tokenizer.word_index) + 1\n\ninput_sequences = []\nfor i in range(1, len(text.split())):\n    n_gram_sequence = text.split()[:i+1]\n    input_sequences.append(\" \".join(n_gram_sequence))\n\nmax_sequence_len = max([len(seq.split()) for seq in input_sequences])\ninput_sequences = pad_sequences(tokenizer.texts_to_sequences(input_sequences),\n                                maxlen=max_sequence_len, padding='pre')\n\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\ny = to_categorical(y, num_classes=total_words)\n\nmodel = Sequential()\nmodel.add(Embedding(total_words, 50, input_length=max_sequence_len-1))\nmodel.add(LSTM(100))\nmodel.add(Dense(total_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X, y, epochs=100, verbose=1)\n\ndef generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted = np.argmax(model.predict(token_list), axis=-1)\n        output_word = \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n        seed_text += \" \" + output_word\n    return seed_text\n\ngenerated_text = generate_text(\"Computer\", next_words=20, model=model, max_sequence_len=max_sequence_len)\nprint(generated_text)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}